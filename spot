#!/bin/bash
# Spot - Local AI Agent Launcher
# This script bootstraps the environment and launches Spot

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
SPOT_MODELS="$SCRIPT_DIR/models"
OLLAMA_MODELS="$HOME/.ollama/models"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

log_info() { echo -e "${GREEN}[Spot]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[Spot]${NC} $1"; }
log_error() { echo -e "${RED}[Spot]${NC} $1"; }

# Check if Ollama is installed, auto-install if missing
check_ollama() {
    if ! command -v ollama &> /dev/null; then
        log_warn "Ollama not installed. Installing..."
        curl -fsSL https://ollama.com/install.sh | sh
        if ! command -v ollama &> /dev/null; then
            log_error "Failed to install Ollama"
            exit 1
        fi
        log_info "Ollama installed successfully"
    fi
    log_info "Ollama found: $(which ollama)"
}

# Check Bun binary compatibility, download correct version if needed
check_bun() {
    local BUN_BIN="$SCRIPT_DIR/bin/bun"
    local ARCH=$(uname -m)

    # Test if bundled Bun works
    if [ -x "$BUN_BIN" ] && "$BUN_BIN" --version &> /dev/null; then
        log_info "Bun ready: $("$BUN_BIN" --version)"
        return 0
    fi

    log_warn "Bundled Bun not compatible with this system ($ARCH)"
    log_info "Downloading correct Bun binary..."

    mkdir -p "$SCRIPT_DIR/bin"

    # Download Bun for this architecture
    case "$ARCH" in
        x86_64)
            curl -fsSL https://github.com/oven-sh/bun/releases/latest/download/bun-linux-x64.zip -o /tmp/bun.zip
            ;;
        aarch64|arm64)
            curl -fsSL https://github.com/oven-sh/bun/releases/latest/download/bun-linux-aarch64.zip -o /tmp/bun.zip
            ;;
        *)
            log_error "Unsupported architecture: $ARCH"
            exit 1
            ;;
    esac

    unzip -o /tmp/bun.zip -d /tmp/bun-extract
    mv /tmp/bun-extract/bun*/bun "$BUN_BIN"
    chmod +x "$BUN_BIN"
    rm -rf /tmp/bun.zip /tmp/bun-extract

    if "$BUN_BIN" --version &> /dev/null; then
        log_info "Bun installed: $("$BUN_BIN" --version)"
    else
        log_error "Failed to install Bun"
        exit 1
    fi
}

# Detect GPU capabilities
detect_gpu() {
    # Check for AMD GPU via sysfs or lspci
    for card in /sys/class/drm/card*/device/vendor; do
        if [ -f "$card" ]; then
            vendor=$(cat "$card" 2>/dev/null)
            if [ "$vendor" = "0x1002" ]; then
                log_info "AMD GPU detected"
                export SPOT_GPU="amd"
                return 0
            elif [ "$vendor" = "0x10de" ]; then
                log_info "NVIDIA GPU detected"
                export SPOT_GPU="nvidia"
                return 0
            fi
        fi
    done

    # Fallback to command-line tools
    if command -v nvidia-smi &> /dev/null && nvidia-smi &> /dev/null; then
        log_info "NVIDIA GPU detected"
        export SPOT_GPU="nvidia"
    elif lspci 2>/dev/null | grep -qi "amd.*radeon\|amd.*display\|ati.*radeon"; then
        log_info "AMD GPU detected"
        export SPOT_GPU="amd"
    elif lspci 2>/dev/null | grep -qi "nvidia"; then
        log_info "NVIDIA GPU detected"
        export SPOT_GPU="nvidia"
    else
        # No GPU found - but don't warn, Ollama will handle it
        export SPOT_GPU="cpu"
    fi
}

# Set up model symlink
setup_models() {
    # Check if models exist on the SSD
    if [ ! -d "$SPOT_MODELS" ]; then
        log_error "Models directory not found at $SPOT_MODELS"
        exit 1
    fi

    # Create .ollama directory if it doesn't exist
    mkdir -p "$HOME/.ollama"

    # Check current state of models directory
    if [ -L "$OLLAMA_MODELS" ]; then
        # It's already a symlink - check if it points to our models
        CURRENT_TARGET=$(readlink -f "$OLLAMA_MODELS")
        if [ "$CURRENT_TARGET" = "$SPOT_MODELS" ]; then
            log_info "Models already linked correctly"
            return 0
        else
            log_warn "Models symlink points elsewhere: $CURRENT_TARGET"
            log_info "Updating symlink to Spot models..."
            rm "$OLLAMA_MODELS"
            ln -s "$SPOT_MODELS" "$OLLAMA_MODELS"
        fi
    elif [ -d "$OLLAMA_MODELS" ]; then
        # It's a real directory - back it up and create symlink
        log_warn "Found existing models directory, backing up..."
        mv "$OLLAMA_MODELS" "$OLLAMA_MODELS.backup.$(date +%s)"
        ln -s "$SPOT_MODELS" "$OLLAMA_MODELS"
        log_info "Created symlink to Spot models"
    else
        # Doesn't exist - create symlink
        ln -s "$SPOT_MODELS" "$OLLAMA_MODELS"
        log_info "Created symlink to Spot models"
    fi
}

# Start Ollama server if not running
start_ollama() {
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        log_info "Ollama server is running"
    else
        log_info "Starting Ollama server..."
        ollama serve > /dev/null 2>&1 &
        sleep 2
        if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
            log_info "Ollama server started"
        else
            log_error "Failed to start Ollama server"
            exit 1
        fi
    fi
}

# Main
main() {
    log_info "Initializing Spot..."

    check_ollama
    check_bun
    detect_gpu
    setup_models
    start_ollama

    log_info "Launching Spot agent..."
    echo ""

    # Run Spot using bundled Bun
    "$SCRIPT_DIR/bin/bun" run "$SCRIPT_DIR/src/index.ts" "$@"
}

main "$@"
